{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95924489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f86d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and explore data\n",
    "def load_data(file_path, sample_size=100000):\n",
    "    \"\"\"\n",
    "    Load the TII-SSRC-23 Dataset\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the dataset CSV file\n",
    "        sample_size: Number of rows to sample for analysis (default: 100000)\n",
    "        \n",
    "    Returns:\n",
    "        df: Loaded DataFrame (sampled)\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset from {file_path}...\")\n",
    "    # Get total number of rows first (without loading entire file)\n",
    "    total_rows = sum(1 for _ in open(file_path, 'r')) - 1  # subtract header\n",
    "    print(f\"Total rows in dataset: {total_rows}\")\n",
    "    \n",
    "    # Calculate skip rows to get a random sample\n",
    "    import random\n",
    "    if total_rows > sample_size:\n",
    "        skip_rate = max(1, total_rows // sample_size)\n",
    "        # Skip rows but always keep header (row 0)\n",
    "        skip_rows = [i for i in range(1, total_rows + 1) if i % skip_rate != 0]\n",
    "        print(f\"Using a sample of approximately {sample_size} rows...\")\n",
    "        df = pd.read_csv(file_path, skiprows=skip_rows)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def explore_data(df):\n",
    "    \"\"\"\n",
    "    Explore the dataset and print useful information\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to explore\n",
    "    \"\"\"\n",
    "    print(\"\\n===== DATASET EXPLORATION =====\")\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nSummary statistics of numerical features:\")\n",
    "    # Only compute statistics for numeric columns to save memory\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    print(df[numeric_cols].describe())\n",
    "    \n",
    "    print(\"\\nTraffic label distribution:\")\n",
    "    label_dist = df['Label'].value_counts()\n",
    "    print(label_dist)\n",
    "    \n",
    "    print(\"\\nTraffic Type distribution:\")\n",
    "    type_dist = df['Traffic Type'].value_counts()\n",
    "    print(type_dist)\n",
    "    \n",
    "    print(\"\\nTraffic Subtype distribution:\")\n",
    "    subtype_dist = df['Traffic Subtype'].value_counts()\n",
    "    print(subtype_dist)\n",
    "    \n",
    "    # Plotting class distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    label_dist.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Label Distribution')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Traffic Type distribution\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    type_dist.plot(kind='bar', color='lightgreen')\n",
    "    plt.title('Traffic Type Distribution')\n",
    "    plt.xlabel('Traffic Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for missing values (selective columns to save memory)\n",
    "    print(\"\\nChecking for missing values in key columns...\")\n",
    "    key_columns = ['Label', 'Traffic Type', 'Traffic Subtype'] + numeric_cols[:20].tolist()  # First 20 numeric columns\n",
    "    missing_values = df[key_columns].isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"\\nMissing values in selected columns:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in the selected columns.\")\n",
    "\n",
    "# Load the dataset with sampling\n",
    "file_path = \"C:\\\\Users\\\\vansh\\\\Downloads\\\\INTEL-CIC-DIS-2017-18-main\\\\data.csv\"\n",
    "df = load_data(file_path)\n",
    "explore_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18858cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocess data\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Make a copy of the dataframe to avoid modifying the original\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"Missing values before cleaning: {df_cleaned.isnull().sum().sum()}\")\n",
    "df_cleaned = df_cleaned.fillna(0)\n",
    "print(f\"Missing values after cleaning: {df_cleaned.isnull().sum().sum()}\")\n",
    "\n",
    "# Handle infinite values\n",
    "# Process numeric columns only to save memory\n",
    "numeric_cols = df_cleaned.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    df_cleaned[col] = df_cleaned[col].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Remove leading and trailing spaces from column names\n",
    "df_cleaned.columns = df_cleaned.columns.str.strip()\n",
    "\n",
    "# Encode the target variables\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['Label_Encoded'] = label_encoder.fit_transform(df_cleaned['Label'])\n",
    "\n",
    "traffic_type_encoder = LabelEncoder()\n",
    "df_cleaned['Traffic_Type_Encoded'] = traffic_type_encoder.fit_transform(df_cleaned['Traffic Type'])\n",
    "\n",
    "traffic_subtype_encoder = LabelEncoder()\n",
    "df_cleaned['Traffic_Subtype_Encoded'] = traffic_subtype_encoder.fit_transform(df_cleaned['Traffic Subtype'])\n",
    "\n",
    "# Print the label mapping for reference\n",
    "print(\"\\nLabel mapping:\")\n",
    "for label, code in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"{label} -> {code}\")\n",
    "\n",
    "print(\"\\nTraffic Type mapping:\")\n",
    "for label, code in zip(traffic_type_encoder.classes_, traffic_type_encoder.transform(traffic_type_encoder.classes_)):\n",
    "    print(f\"{label} -> {code}\")\n",
    "\n",
    "print(\"\\nTraffic Subtype mapping:\")\n",
    "for label, code in zip(traffic_subtype_encoder.classes_, traffic_subtype_encoder.transform(traffic_subtype_encoder.classes_)):\n",
    "    print(f\"{label} -> {code}\")\n",
    "\n",
    "# Memory optimization: Drop columns we don't need to save memory\n",
    "# Convert to more memory-efficient data types where possible\n",
    "for col in numeric_cols:\n",
    "    if df_cleaned[col].max() < 32767 and df_cleaned[col].min() > -32768:\n",
    "        df_cleaned[col] = df_cleaned[col].astype('int16')\n",
    "    elif df_cleaned[col].max() < 2147483647 and df_cleaned[col].min() > -2147483648:\n",
    "        df_cleaned[col] = df_cleaned[col].astype('int32')\n",
    "    else:\n",
    "        df_cleaned[col] = df_cleaned[col].astype('float32')\n",
    "\n",
    "print(\"\\nMemory usage after optimization:\")\n",
    "print(f\"{df_cleaned.memory_usage().sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature selection\n",
    "# Check available columns in the dataframe\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(df_cleaned.columns.tolist())\n",
    "\n",
    "# Define features for traffic classification - adjust if column names differ\n",
    "# These are the standard features, but check if they exist in your dataframe\n",
    "traffic_features = [col for col in [\n",
    "    'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets', \n",
    "    'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
    "    'Flow Packets/s', 'Flow Bytes/s', 'Flow IAT Mean',\n",
    "    'Fwd Packet Length Mean', 'Bwd Packet Length Mean',\n",
    "    'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n",
    "    'Packet Length Mean', 'Packet Length Std'\n",
    "] if col in df_cleaned.columns]\n",
    "\n",
    "# If key features are missing, select the most relevant numeric features\n",
    "if len(traffic_features) < 10:\n",
    "    print(\"Some key features are missing. Selecting top numeric features instead.\")\n",
    "    # Select numeric features (excluding targets and IDs)\n",
    "    exclude_cols = ['Label', 'Traffic Type', 'Traffic Subtype', \n",
    "                   'Label_Encoded', 'Traffic_Type_Encoded', 'Traffic_Subtype_Encoded',\n",
    "                   'Flow ID', 'Src IP', 'Dst IP', 'Timestamp']\n",
    "    potential_features = [col for col in df_cleaned.select_dtypes(include=['number']).columns \n",
    "                         if col not in exclude_cols]\n",
    "    # Select top 15 features (or all if less than 15)\n",
    "    traffic_features = potential_features[:min(15, len(potential_features))]\n",
    "\n",
    "print(f\"\\nSelected {len(traffic_features)} features for traffic classification:\")\n",
    "print(traffic_features)\n",
    "\n",
    "# Features and target for traffic classification\n",
    "X_traffic = df_cleaned[traffic_features]\n",
    "y_traffic_label = df_cleaned['Label_Encoded']\n",
    "y_traffic_type = df_cleaned['Traffic_Type_Encoded']\n",
    "y_traffic_subtype = df_cleaned['Traffic_Subtype_Encoded']\n",
    "\n",
    "print(f\"\\nX shape: {X_traffic.shape}\")\n",
    "print(f\"y_traffic_label shape: {y_traffic_label.shape}\")\n",
    "print(f\"y_traffic_type shape: {y_traffic_type.shape}\")\n",
    "print(f\"y_traffic_subtype shape: {y_traffic_subtype.shape}\")\n",
    "\n",
    "# Features for threat detection - adjust based on available columns\n",
    "threat_features = [col for col in [\n",
    "    'Flow Duration', 'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
    "    'Packet Length Mean', 'Flow Packets/s', 'Flow Bytes/s',\n",
    "    'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
    "    'Fwd IAT Mean', 'Bwd IAT Mean',\n",
    "    'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', \n",
    "    'FWD Init Win Bytes', 'Bwd Init Win Bytes'\n",
    "] if col in df_cleaned.columns]\n",
    "\n",
    "# If key features are missing, use the same features as traffic classification\n",
    "if len(threat_features) < 10:\n",
    "    print(\"Some key threat detection features are missing. Using traffic features instead.\")\n",
    "    threat_features = traffic_features\n",
    "\n",
    "print(f\"\\nSelected {len(threat_features)} features for threat detection:\")\n",
    "print(threat_features)\n",
    "\n",
    "# Features and target for threat detection\n",
    "X_threat = df_cleaned[threat_features]\n",
    "y_threat = df_cleaned['Label_Encoded']\n",
    "\n",
    "print(f\"\\nX shape: {X_threat.shape}, y shape: {y_threat.shape}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5022d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Feature scaling\n",
    "scaler_traffic = StandardScaler()\n",
    "X_traffic_scaled = scaler_traffic.fit_transform(X_traffic)\n",
    "\n",
    "scaler_threat = StandardScaler()\n",
    "X_threat_scaled = scaler_threat.fit_transform(X_threat)\n",
    "\n",
    "print(\"Features scaled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Split data\n",
    "# Split data for traffic classification (Label)\n",
    "X_train_traffic_label, X_test_traffic_label, y_train_traffic_label, y_test_traffic_label = train_test_split(\n",
    "    X_traffic_scaled, y_traffic_label, test_size=0.3, random_state=42, stratify=y_traffic_label\n",
    ")\n",
    "\n",
    "# Split data for traffic type classification\n",
    "X_train_traffic_type, X_test_traffic_type, y_train_traffic_type, y_test_traffic_type = train_test_split(\n",
    "    X_traffic_scaled, y_traffic_type, test_size=0.3, random_state=42, stratify=y_traffic_type\n",
    ")\n",
    "\n",
    "# Split data for traffic subtype classification\n",
    "X_train_traffic_subtype, X_test_traffic_subtype, y_train_traffic_subtype, y_test_traffic_subtype = train_test_split(\n",
    "    X_traffic_scaled, y_traffic_subtype, test_size=0.3, random_state=42, stratify=y_traffic_subtype\n",
    ")\n",
    "\n",
    "# Split data for threat detection\n",
    "X_train_threat, X_test_threat, y_train_threat, y_test_threat = train_test_split(\n",
    "    X_threat_scaled, y_threat, test_size=0.3, random_state=42, stratify=y_threat\n",
    ")\n",
    "\n",
    "print(\"Data split complete!\")\n",
    "print(f\"Traffic Label Classification - Training set: {X_train_traffic_label.shape}, Test set: {X_test_traffic_label.shape}\")\n",
    "print(f\"Traffic Type Classification - Training set: {X_train_traffic_type.shape}, Test set: {X_test_traffic_type.shape}\")\n",
    "print(f\"Traffic Subtype Classification - Training set: {X_train_traffic_subtype.shape}, Test set: {X_test_traffic_subtype.shape}\")\n",
    "print(f\"Threat Detection - Training set: {X_train_threat.shape}, Test set: {X_test_threat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ff456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define model training and evaluation functions\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, class_names, model_type=\"traffic\"):\n",
    "    \"\"\"Train and evaluate classification model\"\"\"\n",
    "    \n",
    "    # Initialize models\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    print(f\"Training Random Forest model for {model_type} classification...\")\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Train Decision Tree model\n",
    "    print(f\"Training Decision Tree model for {model_type} classification...\")\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    y_pred_dt = dt_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Random Forest model\n",
    "    print(\"\\nRandom Forest Model Evaluation:\")\n",
    "    rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "    \n",
    "    # Evaluate Decision Tree model\n",
    "    print(\"\\nDecision Tree Model Evaluation:\")\n",
    "    dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "    print(f\"Accuracy: {dt_accuracy:.4f}\")\n",
    "    \n",
    "    # Print classification report for Random Forest\n",
    "    print(\"\\nRandom Forest Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=class_names))\n",
    "    \n",
    "    return rf_model, dt_model, y_pred_rf, y_pred_dt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model, feature_names, title):\n",
    "    \"\"\"Plot feature importance\"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(title)\n",
    "    plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 10 features\n",
    "    print(\"Top 10 important features:\")\n",
    "    for i in range(min(10, len(indices))):\n",
    "        print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec669e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Train and evaluate traffic label classification model\n",
    "label_class_names = label_encoder.classes_\n",
    "rf_label, dt_label, y_pred_rf_label, y_pred_dt_label = train_and_evaluate_model(\n",
    "    X_train_traffic_label, X_test_traffic_label, y_train_traffic_label, y_test_traffic_label, \n",
    "    label_class_names, \"traffic label\"\n",
    ")\n",
    "\n",
    "# Plot confusion matrix for traffic label classification (Random Forest)\n",
    "plot_confusion_matrix(\n",
    "    y_test_traffic_label, \n",
    "    y_pred_rf_label, \n",
    "    label_class_names,\n",
    "    \"Traffic Label Classification - Random Forest Confusion Matrix\"\n",
    ")\n",
    "\n",
    "# Plot traffic label classification feature importance\n",
    "plot_feature_importance(\n",
    "    rf_label, \n",
    "    traffic_features, \n",
    "    \"Traffic Label Classification Feature Importance\"\n",
    ")\n",
    "\n",
    "# Plot decision tree\n",
    "plt.figure(figsize=(20, 15))\n",
    "plot_tree(\n",
    "    dt_label, \n",
    "    feature_names=traffic_features, \n",
    "    class_names=label_class_names,\n",
    "    filled=True, \n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"AI-Powered Traffic Label Classification Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69263499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train and evaluate traffic type classification model\n",
    "type_class_names = traffic_type_encoder.classes_\n",
    "rf_type, dt_type, y_pred_rf_type, y_pred_dt_type = train_and_evaluate_model(\n",
    "    X_train_traffic_type, X_test_traffic_type, y_train_traffic_type, y_test_traffic_type, \n",
    "    type_class_names, \"traffic type\"\n",
    ")\n",
    "\n",
    "# Plot confusion matrix for traffic type classification (Random Forest)\n",
    "plot_confusion_matrix(\n",
    "    y_test_traffic_type, \n",
    "    y_pred_rf_type, \n",
    "    type_class_names,\n",
    "    \"Traffic Type Classification - Random Forest Confusion Matrix\"\n",
    ")\n",
    "\n",
    "# Plot traffic type classification feature importance\n",
    "plot_feature_importance(\n",
    "    rf_type, \n",
    "    traffic_features, \n",
    "    \"Traffic Type Classification Feature Importance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Train and evaluate traffic subtype classification model\n",
    "subtype_class_names = traffic_subtype_encoder.classes_\n",
    "rf_subtype, dt_subtype, y_pred_rf_subtype, y_pred_dt_subtype = train_and_evaluate_model(\n",
    "    X_train_traffic_subtype, X_test_traffic_subtype, y_train_traffic_subtype, y_test_traffic_subtype, \n",
    "    subtype_class_names, \"traffic subtype\"\n",
    ")\n",
    "\n",
    "# Plot confusion matrix for traffic subtype classification (Random Forest)\n",
    "plot_confusion_matrix(\n",
    "    y_test_traffic_subtype, \n",
    "    y_pred_rf_subtype, \n",
    "    subtype_class_names,\n",
    "    \"Traffic Subtype Classification - Random Forest Confusion Matrix\"\n",
    ")\n",
    "\n",
    "# Plot traffic subtype classification feature importance\n",
    "plot_feature_importance(\n",
    "    rf_subtype, \n",
    "    traffic_features, \n",
    "    \"Traffic Subtype Classification Feature Importance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022be2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Train and evaluate threat detection model\n",
    "rf_threat, dt_threat, y_pred_rf_threat, y_pred_dt_threat = train_and_evaluate_model(\n",
    "    X_train_threat, X_test_threat, y_train_threat, y_test_threat, \n",
    "    label_class_names, \"threat\"\n",
    ")\n",
    "\n",
    "# Plot confusion matrix for threat detection (Random Forest)\n",
    "plot_confusion_matrix(\n",
    "    y_test_threat, \n",
    "    y_pred_rf_threat, \n",
    "    label_class_names,\n",
    "    \"Threat Detection - Random Forest Confusion Matrix\"\n",
    ")\n",
    "\n",
    "# Plot threat detection feature importance\n",
    "plot_feature_importance(\n",
    "    rf_threat, \n",
    "    threat_features, \n",
    "    \"Threat Detection Feature Importance\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plot_tree(\n",
    "    dt_threat, \n",
    "    feature_names=threat_features, \n",
    "    class_names=label_class_names,\n",
    "    filled=True, \n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"Threat Detection & Anomaly Identification Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create prediction functions\n",
    "def predict_traffic(model, scaler, features, feature_names, class_names):\n",
    "    \"\"\"\n",
    "    Predict traffic characteristics for new data\n",
    "    \"\"\"\n",
    "    # Create a dataframe with the feature names\n",
    "    input_df = pd.DataFrame([features], columns=feature_names)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaled_features = scaler.transform(input_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(scaled_features)\n",
    "    \n",
    "    # Get the predicted class name\n",
    "    predicted_class = class_names[prediction[0]]\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = model.predict_proba(scaled_features)[0]\n",
    "    \n",
    "    return predicted_class, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ac885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Example prediction\n",
    "# Example new traffic data (replace with actual values)\n",
    "# Format: [Flow Duration, Total Fwd Packet, Total Bwd packets, ...]\n",
    "# These values should match the order of traffic_features\n",
    "\n",
    "new_traffic_data = [\n",
    "    5.0,        # Flow Duration\n",
    "    50,         # Total Fwd Packet\n",
    "    30,         # Total Bwd packets\n",
    "    10000,      # Total Length of Fwd Packet\n",
    "    5000,       # Total Length of Bwd Packet\n",
    "    16.0,       # Flow Packets/s\n",
    "    3000.0,     # Flow Bytes/s\n",
    "    0.1,        # Flow IAT Mean\n",
    "    200,        # Fwd Packet Length Mean\n",
    "    166.6,      # Bwd Packet Length Mean\n",
    "    185.7,      # Average Packet Size\n",
    "    200,        # Fwd Segment Size Avg\n",
    "    166.6,      # Bwd Segment Size Avg\n",
    "    185.7,      # Packet Length Mean\n",
    "    20          # Packet Length Std\n",
    "]\n",
    "\n",
    "# Make predictions for the new traffic data\n",
    "print(\"\\n--- Traffic Label Prediction ---\")\n",
    "predicted_label, label_probabilities = predict_traffic(\n",
    "    rf_label, \n",
    "    scaler_traffic, \n",
    "    new_traffic_data, \n",
    "    traffic_features, \n",
    "    label_class_names\n",
    ")\n",
    "\n",
    "print(f\"Predicted traffic label: {predicted_label}\")\n",
    "print(\"Prediction probabilities:\")\n",
    "for i, class_name in enumerate(label_class_names):\n",
    "    print(f\"{class_name}: {label_probabilities[i]:.4f}\")\n",
    "\n",
    "print(\"\\n--- Traffic Type Prediction ---\")\n",
    "predicted_type, type_probabilities = predict_traffic(\n",
    "    rf_type, \n",
    "    scaler_traffic, \n",
    "    new_traffic_data, \n",
    "    traffic_features, \n",
    "    type_class_names\n",
    ")\n",
    "\n",
    "print(f\"Predicted traffic type: {predicted_type}\")\n",
    "print(\"Prediction probabilities:\")\n",
    "for i, class_name in enumerate(type_class_names):\n",
    "    print(f\"{class_name}: {type_probabilities[i]:.4f}\")\n",
    "\n",
    "print(\"\\n--- Traffic Subtype Prediction ---\")\n",
    "predicted_subtype, subtype_probabilities = predict_traffic(\n",
    "    rf_subtype, \n",
    "    scaler_traffic, \n",
    "    new_traffic_data, \n",
    "    traffic_features, \n",
    "    subtype_class_names\n",
    ")\n",
    "\n",
    "print(f\"Predicted traffic subtype: {predicted_subtype}\")\n",
    "print(\"Prediction probabilities:\")\n",
    "for i, class_name in enumerate(subtype_class_names):\n",
    "    print(f\"{class_name}: {subtype_probabilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd90e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Save models\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the traffic classification models\n",
    "with open('models/rf_label_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_label, f)\n",
    "\n",
    "with open('models/dt_label_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_label, f)\n",
    "\n",
    "with open('models/rf_type_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_type, f)\n",
    "\n",
    "with open('models/dt_type_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_type, f)\n",
    "\n",
    "with open('models/rf_subtype_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_subtype, f)\n",
    "\n",
    "with open('models/dt_subtype_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_subtype, f)\n",
    "\n",
    "# Save the threat detection models\n",
    "with open('models/rf_threat_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_threat, f)\n",
    "\n",
    "with open('models/dt_threat_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_threat, f)\n",
    "\n",
    "# Save the scalers\n",
    "with open('models/scaler_traffic.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_traffic, f)\n",
    "\n",
    "with open('models/scaler_threat.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_threat, f)\n",
    "\n",
    "# Save the encoders\n",
    "with open('models/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "with open('models/traffic_type_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(traffic_type_encoder, f)\n",
    "\n",
    "with open('models/traffic_subtype_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(traffic_subtype_encoder, f)\n",
    "\n",
    "print(\"Models, scalers, and encoders saved successfully in the 'models' directory!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
